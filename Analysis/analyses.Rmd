---
title: "Analyses for DIAG-NonParty-Radio"
output: 
  html_notebook:
  code_folding: hide
---

```{r setup, include = FALSE}
# R version 4.2.3
# load packages & set options
library(parallel)
library(ggpubr) # ggpubr_0.6.0
library(here) # here_1.0.1
library(rstatix) # rstatix_0.7.2
library(showtext) # showtext_0.9-6
library(tidyverse) # tidyverse_2.0.0
knitr::opts_chunk$set(echo = FALSE)

# Read data
dat <- readRDS(here::here("Processed data/processed-data.rds"))

# Demographics
dems <- dat %>%
  select(subject_id, age, pro_age, gender, pro_gender,
    pro_racial_group, partisan_identity, pro_partisan_identity,
    political_ideology, time_taken, time_on_data_security,
    stand_out, deception, deception_coded, further_comments) %>%
  unique()

# Compare qualtrics and prolific demographics
dems_match <- dems %>%
  mutate(
    pro_gender = case_match(pro_gender,
      c("Female") ~ "woman",
      c("Male") ~ "man")) %>%
  mutate(partisan_change = ifelse(
    as.character(partisan_identity) != as.character(pro_partisan_identity),
    paste(pro_partisan_identity, partisan_identity, sep = " -> "), NA)) %>%
  mutate(
    age_match = age == pro_age,
    gender_match = as.character(gender) == as.character(pro_gender),
    par_id_match = as.character(partisan_identity) == as.character(pro_partisan_identity) # nolint
  ) %>%
  select(subject_id, age_match, gender_match, par_id_match, partisan_change)

# summarise(dems_match, across(matches("_match"), ~sum(.))) / 360
# table(dems_match$partisan_change)

# Add custom font for plots
font_add("Nunito",
  regular = "~/Library/Fonts/NunitoSans-Regular.ttf",
  italic = "~/Library/Fonts/NunitoSans-Italic.ttf",
  bold = "~/Library/Fonts/NunitoSans-Bold.ttf",
  bolditalic = "~/Library/Fonts/NunitoSans-BoldItalic.ttf")
showtext_auto()

# Custom functions
formp <- function(p, text = FALSE) {
  ## ---------------------------
  ## Format p values
  ##
  ## This function takes in a number between
  ## zero and one or a formatted p-value and outputs
  ## a formatted p-value. If p-value is already formatted
  ## then applying the function changes the format from
  ## "p = .034" to ".034" and vice versa.
  ##
  ## @p p-value to be formatted
  ## @text adds "p = " or "p < " to output
  ##
  ## @out string with formatted p-value
  ## ---------------------------

  # If already formatted but no "p" then add "p"
  if (grepl("^<.\\d{3}$", p)) {
  out <- gsub("<", "p < ", p)
  } else if (grepl("^.\\d{3}$", p)) {
  out <- gsub("^", "p = ", p)
  # If already formatted and "p" then remove "p"
  } else if (grepl("^p < .\\d{3}$", p)) {
  out <- gsub("p < ", "<", p)
  } else if (grepl("^p = .\\d{3}$", p)) {
  out <- gsub("p = ", "", p)
  # If not yet formatted and smaller than .001
  } else if (is.numeric(p) && p < 0.001) {
  if (text) {
    out <- "p < .001"
  } else {
    out <- "<.001"
  }
  # If not yet formatted and bigger than .001
  } else if (p >= 0.001) {
  p <- format(round(p, 3), nsmall = 3, scientific = FALSE)
  p <- sub("0.", ".", p)
  if (text) {
    out <- paste("p =", p)
  } else {
    out <- p
  }
  }
  return(out)
}
forma <- function(number, dec = NULL, lead_zero = TRUE) { # nolint
  ## ---------------------------
  ## Format values in apa style
  ##
  ## This function takes in a number and outputs
  ## a formatted number. If no decimal is provided, then
  ## it uses a heuristic to round the number. If lead_zero
  ## is set to FALSE, then the lead zero of the number is
  ## removed (useful for p-values or eta squared).
  ##
  ## @number input number
  ## @dec optional number of decimals
  ## @lead_zero keep leading zero
  ##
  ## @out formatted number
  ## ---------------------------

  # If dec is logical, interpret as lead_zero
  if (is.logical(dec)) {
  lead_zero <- dec
  dec <- NULL
  }
  # If no decimal is specified, use heuristic
  if (!is.null(dec)) {
  } else if (abs(number) >= 100) {
    dec <- 0
  } else if (abs(number) >= 10 && number < 100) {
    dec <- 1
  } else if (abs(number) >= 0.1 && number < 10) {
    dec <- 2
  } else if (abs(number) >= 0.001 && number < 0.1) {
    dec <- 3
  } else if (abs(number) < 0.001 && number != 0) {
    dec <- stringr::str_locate(format(
      abs(number), scientific = FALSE), "[1-9]{1}")[1] - 2
  } else if (number == 0) {
    dec <- 0
  }
  # Round number to decimal
  out <- format(round(number, dec), nsmall = dec, scientific = FALSE)
  # Remove leading zero if required
  if (out < 1 && lead_zero == FALSE) {
  out <- sub("0.", ".", out)
  }
  return(out)
}
report_desc <- function(descriptives, line) {
  ## ---------------------------
  ## Report descriptive statistics
  ##
  ## Takes a data.frame containing descriptive
  ## results and outputs a manuscript-ready string
  ## containing the mean and standard deviation
  ## e.g., "(M = 4.45, SD = 1.29)"
  ##
  ## @param descriptives -- data.frame with
  ##        descriptive data
  ## @param line -- line of descriptives data
  ##        to report
  ##
  ## @return string string containing M and SD
  ## ---------------------------
  out <- paste0(
    "(M = ",
    forma(descriptives$mean[line]),
    ", SD = ",
    forma(descriptives$sd[line]),
    ")")
  return(out)
}
theme_cs_talk <- function(font = "Nunito", lab_size = 16, label_size = 14,
  dark = "#465263", light = "#E1E9ED", solid_facet = TRUE) {
  if (solid_facet) {
  facet_fill <- dark
  facet_text <- light
  } else if (!solid_facet) {
  facet_fill <- "transparent"
  facet_text <- dark
  }
  theme_bw(base_size = 16) %+replace%
  theme(
  # Rectangle elements
  plot.background = element_rect(fill = "transparent",
    color = NA_character_),
  panel.background = element_rect(fill = "transparent"),
  legend.background = element_rect(fill = "transparent", color = NA),
  strip.background = element_rect(color = facet_fill,
    fill = facet_fill, linewidth = 1),
  # Text elements
  plot.title = element_text(family = font, size = lab_size,
    face = "bold", hjust = 0, vjust = 2, color = dark),
  plot.subtitle = element_text(family = font,
    size = lab_size - 2, color = dark),
  plot.caption = element_text(family = font, size = lab_size,
    hjust = 1, color = dark),
  axis.title = element_text(family = font, size = lab_size,
    color = dark),
  axis.text = element_text(family = font, size = label_size,
    color = dark),
  axis.text.x = element_text(margin = margin(5, b = 10),
    color = dark),
  legend.title = element_text(family = font, size = lab_size,
    color = dark, hjust = 0),
  legend.text = element_text(family = font, size = label_size,
    color = dark),
  strip.text = element_text(family = font, size = label_size,
    color = facet_text, margin = margin(4, 4, 4, 4)),
  # Line elements
  axis.ticks = element_line(color = dark, linewidth = 0.5),
  legend.key = element_rect(fill = "transparent", color = NA_character_),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.border = element_rect(color = dark, fill = NA, linewidth = 1)
  )
}
```

### Sample Characteristics
We collected data from a total of N = 389 participants using a Prolific representative sample that was stratified on the basis of age, sex, ethnicity, and political affiliation. Following our exclusion criteria we had to exclude 28 participants who inferred the wrong category in five or more non-target inference items and one participant who rated their own data to be unfit for analysis. This resulted in N = 360 valid datasets (175 men, 180 women, 4 non-binary, 1 n/a; median age Mdn = `r round(median(dems$age, na.rm = TRUE), 1)` years, ranging from `r min(dems$age, na.rm = TRUE)` to `r max(dems$age, na.rm = TRUE)`). 42% of participants identified as Democrats, 23% as Independents, 33% as Republicans, and 2% as other. According to Prolific demographics, more participants identified as Independents (31% Democrats, 42% Independents, 27% Republicans)â€“possibly because there was no "Independent" option in our survey. Participants received monetary compensation of 1.20 GBP for completing the 8-minute study. Participants' mean political ideology was M = `r round(mean(dems$political_ideology, na.rm = TRUE), 1)` (SD = `r round(sd(dems$political_ideology, na.rm = TRUE), 1)`), on a scale from 0 = conservative to 100 = liberal. 80 additional people started the experiment on prolific but returned their submission, timed-out, did not meet the inclusion criteria, or failed the comprehension check.

### Exclusion of Statistical Outliers
We did not preregister exclusion of statistical outliers. However, upon inspection of the data we noticed that there were many data points that were very unlikely to reflect true inferences. That is, some participants in both the stereotype-disconfirming and the stereotype-confirming condition seemed to infer categories from opinions that are stereotypically associated with the opposing category (e.g., inferring from a pro-gun control opinion that the person must be a Republican). We assume that such responses are likely due to the participants understanding the items the wrong way around or responding at random. To investigate the potential effect of these outliers we conducted additional analyses excluding them. Theoretically, any values below the scale midpoint (50) are very unlikely to reflect genuine inferences, because they would indicate that the category that is not stereotypically associated with the opinion is more likely to express the opinion than the category that is stereotypically associated with it. While it would therefore seem appropriate to exclude any values below 50, we decided to exclude values below 40, to account for the fact that participants may respond somewhat inaccurately using the sliding scale. For the main analyses we report tests with and without this exclusion criterion.

A similar problem occurred for the stereotype measure on which some participants indicated that category members would on average strongly disagree with opinions that are stereotypical for their category. However, for this measure there is less of a clear cutoff, because even an opinion that is very stereotypical or diagnostic for a category must not be shared by a majority of its members (as long as it is shared by considerably less members of the opposing category). To nevertheless investigate the effect of these outliers we conducted a multiverse analysis using several different cutoff criteria.

### Manipulation Check
#### Stereotype Measure {.tabset}
```{r stereotype ~ typicality * category_type, warning = FALSE, message = FALSE}
# Stereotype data
stereo_dat <- dat %>%
  filter(item_type == "target") %>%
  filter(diagnosticity_component == "COUNTERPROB")
```

##### Multiverse Outlier Correction
```{r stereotype ~ typicality * category_type multiverse, warning = FALSE, message = FALSE}
# Loop over all combinations of cutoffs and transformations
mv_stereo <- data.frame(
  cutoff = c("none", "fixed 1", "fixed 10", "fixed 20", "fixed 30", "fixed 40"),
  cutoff_value = c(0, 1, 10, 20, 30, 40))
for (c in seq_len(nrow(mv_stereo))) {
  mv_dat <- stereo_dat %>%
    filter(stereo >= mv_stereo$cutoff_value[c])

  # Run ANOVA
  mv_mod <- mv_dat %>%
    anova_test(dv = stereo,
      effect.size = "pes",
      between = c(category_type, typicality)) %>%
    as_tibble() %>%
    rowwise() %>%
    mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

  # Save test statistics for h1
  mv_stereo$`n excluded`[c] <-
    nrow(stereo_dat) - nrow(mv_dat)
  mv_stereo$ct_DFn[c] <- mv_mod$DFn[1]
  mv_stereo$ct_DFd[c] <- mv_mod$DFd[1]
  mv_stereo$ct_F[c] <- mv_mod$F[1]
  mv_stereo$ct_p[c] <- mv_mod$p[1]
  mv_stereo$ct_pes[c] <- mv_mod$pes[1]
  mv_stereo$typ_DFn[c] <- mv_mod$DFn[2]
  mv_stereo$typ_DFd[c] <- mv_mod$DFd[2]
  mv_stereo$typ_F[c] <- mv_mod$F[2]
  mv_stereo$typ_p[c] <- mv_mod$p[2]
  mv_stereo$typ_pes[c] <- mv_mod$pes[2]
  mv_stereo$int_DFn[c] <- mv_mod$DFn[3]
  mv_stereo$int_DFd[c] <- mv_mod$DFd[3]
  mv_stereo$int_F[c] <- mv_mod$F[3]
  mv_stereo$int_p[c] <- mv_mod$p[3]
  mv_stereo$int_pes[c] <- mv_mod$pes[3]
}
# Print multiverse table
knitr::kable(select(mv_stereo, - cutoff_value),
  format = "markdown")
```

To test whether the manipulation was successful, we conducted a multiverse analysis with multiple fixed outlier cutoffs. We excluded participants with values below 1, 10, 20, 30, or 40 and conducted a two-way between-subjects ANOVA with the stereotype measure as the dependent variable and typicality and category type as between-subjects factors. The effect of typicality was marginally significant with no outlier exclusion and significant with all different outlier thresholds. The effect of category type and the two-way interaction were not significant in any of the tests. These results provide moderate support for the effectiveness of our manipulation.

##### Outlier Detection
```{r stereotype ~ typicality * category_type outlier, warning = FALSE, message = FALSE}
stereo_dat %>%
  ggplot(., aes(typicality, stereo, color = category_type)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge()) +
  labs(x = "Typicality", y = "Stereotype", color = "Category Type") +
  scale_color_manual(values = c("#849AB9", "#465263")) +
  theme_cs_talk()
```

##### QQ-Plot
```{r stereotype ~ typicality * category_type qq, message = FALSE}
stereo_dat %>%
  ggplot(., aes(sample = stereo)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#000000") +
  stat_qq_line(color = "#000000") +
  facet_grid(category_type ~ typicality, labeller = "label_value") +
  theme_cs_talk()
```

### Party Inferences
#### Counterstereotype Probability {.tabset}
```{r target inference party ~ typicality, warning = FALSE, message = FALSE}
# PREREGISTERED
# Inference data
inf_dat <- dat %>%
  filter(diagnosticity_component == "COUNTERPROB") %>%
  filter(category_type == "PARTY") %>%
  filter(item_type == "target")

# Descriptives
inf_desc <- inf_dat %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_t <- inf_dat %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_d <- inf_dat %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_report <- paste0("t(", inf_t$df, ") = ",
  inf_t$statistic, ", ", inf_t$p, ", d = ",
  inf_d)

# WITH OUTLIER EXCLUSION
# Exclude outliers
inf_dat_ex <- inf_dat %>%
  filter(inf >= 40)

# Descriptives
inf_ex_desc <- inf_dat_ex %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_ex_t <- inf_dat_ex %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_ex_d <- inf_dat_ex %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_ex_report <- paste0("t(", inf_ex_t$df, ") = ",
  inf_ex_t$statistic, ", ", inf_ex_t$p, ", d = ",
  inf_ex_d)

# WILCOXON
# One-sided Wilcoxon rank-sum test
inf_wcx <- inf_dat %>%
  wilcox_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS")

# Wilcoxon effect size r
inf_wcx_r <- inf_dat %>%
  wilcox_effsize(inf ~ typicality,
  ref.group = "DIS") %>%
  pull(effsize)

# Print wilcoxon test
inf_wcx_report <- paste0("Z = ", forma(inf_wcx_r * sqrt(nrow(inf_dat) / 2)),
  ", ", formp(inf_wcx$p, TRUE), ", r = ", forma(inf_wcx_r))
```

To test our hypothesis in the party category condition, we conducted a preregistered one-sided independent samples t-test comparing target inferences of partisanship in the stereotype-confirming and stereotype-disconfirming conditions. The target inferences in the disconfirming condition `r report_desc(inf_desc, 1)` were not significantly lower than in the stereotype-confirming condition `r report_desc(inf_desc, 2)`, `r inf_report`. To investigate whether this was due to statistical outliers, we conducted another independent samples t-test excluding participants with values below 40. After exclusion, the inferences in the disconfirming condition `r report_desc(inf_ex_desc, 1)` were significantly lower than in the confirming condition `r report_desc(inf_ex_desc, 2)`, `r inf_ex_report`.

##### Descriptives
```{r target inference party ~ time * typicality descriptives}
knitr::kable(inf_desc, format = "markdown")
```

##### Outlier Detection
```{r target inference party ~ typicality outlier, warning = FALSE, message = FALSE, fig.width = 4}
inf_dat %>%
  ggplot(., aes(typicality, inf)) +
  geom_boxplot(outlier.shape = NA, color = "#465263") +
  geom_jitter(width = 0.2, color = "#465263") +
  labs(x = "Typicality", y = "Inferences") +
  theme_cs_talk()
```

##### Multiverse Outlier Correction
```{r target inference party ~ typicality multiverse, warning = FALSE, message = FALSE}
# Loop over all combinations of cutoffs and transformations
mv <- data.frame(
  cutoff = c("none", "fixed 20", "fixed 30", "fixed 40",
    "Mdn Â± 2.5 IQR", "Mdn Â± 2.0 IQR", "Mdn Â± 1.5 IQR", "Mdn Â± 1.0 IQR"),
  cutoff_type = c("fixed", "fixed", "fixed", "fixed",
    "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR"),
  cutoff_value = c(0, 20, 30, 40, 2.5, 2.0, 1.5, 1.0))
for (c in seq_len(nrow(mv))) {
  if (mv$cutoff_type[c] == "fixed") {
    mv_dat <- inf_dat %>%
      filter(inf >= mv$cutoff_value[c])
  } else if (mv$cutoff_type[c] == "Mdn Â± IQR") {
    mv_dat <- inf_dat %>%
      group_by(typicality) %>%
      filter(!is_outlier(inf, coef = mv$cutoff_value[c])) %>%
      ungroup()
  }
  # Independent samples t-test
  mv_t <- mv_dat %>%
    t_test(
      inf ~ typicality,
      alternative = "less",
      ref.group = "DIS") %>%
    mutate(p = formp(p, text = FALSE), df = forma(df, 2),
      statistic = forma(statistic))

  # Cohens d
  mv_d <- mv_dat %>%
    cohens_d(inf ~ typicality) %>%
    pull(effsize) %>%
    forma()

  # Save test statistics for h1
  mv$`n excluded`[c] <- nrow(inf_dat) - nrow(mv_dat)
  mv$df[c] <- mv_t$df
  mv$t[c] <- mv_t$statistic
  mv$p[c] <- mv_t$p
  mv$d[c] <- mv_d
}
# Print multiverse table
knitr::kable(select(mv, -cutoff_type, - cutoff_value), format = "markdown")
```

To investigate the robustness of the effect across various outlier exclusion criteria, we conducted a multiverse analysis. We performed independent samples t-tests across several fixed and distribution-based thresholds. For the fixed thresholds we excluded ratings below 20, 30, or 40 uniformly across both experimental conditions. For the distribution-based criteria we excluded ratings that were 1.0, 1.5, 2.0, or 2.5 times the IQR above or below the condition median. The effect was significant across all seven thresholds. These results suggest that the effect may have been obscured due to model outliers. However, removing outliers may also have introduced bias, for instance if we inadvertantly removed more true model outliers in one of the two experimental conditions. This risk is especially high with the distribution-based thresholds we used: If in the disconfirming condition the distribution of inferences is shifted towards the scale midpoint, this would make low outliers more difficult to detect (due to a floor effect). Thus, applying the thresholds may have artificially inflated the effect by predominantly removing low outliers in the confirming condition. As this risk is reduced by the fixed thresholds, these provide a more conservative estimate of the true effect.

##### QQ-Plot
```{r target inference party ~ typicality qq, message = FALSE}
inf_dat_ex %>%
  ggplot(., aes(sample = inf)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#000000") +
  stat_qq_line(color = "#000000") +
  facet_grid(~ typicality, labeller = "label_value") +
  theme_cs_talk()
```

##### Moderation by partisanship
```{r target inference party ~ typicality * partisanship}
# Prepare data
inf_par_dat <- inf_dat_ex %>%
  # Select participants who identify as Republican, Democrat, or Independent
  filter(partisan_identity %in% c("Republican", "Democrat", "Independent"))

# Descriptives
inf_par_desc <- inf_par_dat %>%
  group_by(partisan_identity, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
inf_par_mod <- inf_par_dat %>%
  anova_test(dv = inf,
    effect.size = "pes",
    between = c(partisan_identity, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

knitr::kable(inf_par_mod, format = "markdown")
```

It may be possible that the effect of diagnosticity on the inferences depends on the participant's partisanship. To test this, we conducted a two-way between-subjects ANOVA with the target inference as the dependent variable and the participants' party identification and typicality as between-subjects factors. We found a significant effect of typicality. All other effects were non-significant.

##### Moderation by partisan fit
```{r target inference party ~ typicality * partisan fit}
# Prepare data
inf_par_fit_dat <- inf_dat_ex %>%
  # Select participants who identify with one of the major parties
  filter(partisan_identity %in% c("Republican", "Democrat")) %>%
  # Recode partisan identity
  mutate(partisan_identity = case_match(partisan_identity,
    "Democrat" ~ "DEM", "Republican" ~ "REP")) %>%
  mutate(partisan_fit = as.factor(ifelse(
    partisan_identity == target_category_label,
    "same", "different")))

# Descriptives
inf_par_fit_desc <- inf_par_fit_dat %>%
  group_by(partisan_fit, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
inf_par_fit_mod <- inf_par_fit_dat %>%
  anova_test(dv = inf,
    effect.size = "pes",
    between = c(partisan_fit, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

knitr::kable(inf_par_fit_mod, format = "markdown")
```

It may be possible that the effect of diagnosticity on the inferences depends on the fit between the participant's party identification and the target's partisanship. We therefore ran an exploratory analysis examining the role of ideological fit (i.e., whether participant and target belong to the same category or a different one). We excluded participants classified as Independents and conducted a two-way between-subjects ANOVA with the target inference as the dependent variable and ideological fit and typicality as between-subjects factors. We found a significant effect of typicality. All other effects were non-significant.

##### Moderation by political issue
```{r target inference party ~ typicality * issue}
# Descriptives
inf_issue_desc <- inf_dat_ex %>%
  group_by(issue, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
inf_issue_mod <- inf_dat_ex %>%
  anova_test(dv = inf,
    effect.size = "pes",
    between = c(issue, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

knitr::kable(inf_issue_mod, format = "markdown")
```

We ran another exploratory analysis to test whether the effect of diagnosticity on the inferences was moderated by the issue for which diagnosticity was manipulated. We conducted a two-way between-subjects ANOVA with the target inference as the dependent variable and issue and typicality as between-subjects factors. We found a significant effect of typicality. All other effects were non-significant.

#### Stereotype Probability {.tabset}
```{r target inference party stereoprob ~ typicality, warning = FALSE, message = FALSE}
# Inference data
inf_stereoprob_dat <- dat %>%
  filter(diagnosticity_component == "STEREOPROB") %>%
  filter(category_type == "PARTY") %>%
  filter(item_type == "target")

# Descriptives
inf_stereoprob_desc <- inf_stereoprob_dat %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_stereoprob_t <- inf_stereoprob_dat %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_stereoprob_d <- inf_stereoprob_dat %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_stereoprob_report <- paste0("t(", inf_stereoprob_t$df, ") = ",
  inf_stereoprob_t$statistic, ", ", inf_stereoprob_t$p, ", d = ",
  inf_stereoprob_d)

# EXCLUDE OUTLIERS
inf_stereoprob_dat_ex <- inf_stereoprob_dat %>%
  filter(inf >= 40)

# Descriptives
inf_stereoprob_ex_desc <- inf_stereoprob_dat_ex %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_stereoprob_ex_t <- inf_stereoprob_dat_ex %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_stereoprob_ex_d <- inf_stereoprob_dat_ex %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_stereoprob_ex_report <- paste0("t(", inf_stereoprob_ex_t$df, ") = ",
  inf_stereoprob_ex_t$statistic, ", ", inf_stereoprob_ex_t$p, ", d = ",
  inf_stereoprob_ex_d)

# WILCOXON
# One-sided Wilcoxon rank-sum test
inf_stereoprob_wcx <- inf_stereoprob_dat %>%
  wilcox_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS")

# Wilcoxon effect size r
inf_stereoprob_wcx_r <- inf_stereoprob_dat %>%
  wilcox_effsize(inf ~ typicality,
  ref.group = "DIS") %>%
  pull(effsize)

# Print wilcoxon test
inf_stereoprob_wcx_report <- paste0("Z = ",
  forma(inf_stereoprob_wcx_r * sqrt(nrow(inf_stereoprob_dat) / 2)),
  ", ", formp(inf_stereoprob_wcx$p, TRUE), ", r = ", forma(inf_stereoprob_wcx_r))
```

To test the effect of manipulating the stereotype probability component of diagnosticity on inferences of partisanship, we conducted an exploratory one-sided independent samples t-test comparing target inferences of partisanship in the stereotype-confirming and stereotype-disconfirming conditions. The target inferences in the disconfirming condition `r report_desc(inf_stereoprob_desc, 1)` were not significantly lower than in the stereotype-confirming condition `r report_desc(inf_stereoprob_desc, 2)`, `r inf_stereoprob_report`. To investigate whether this was due to statistical outliers, we conducted another independent samples t-test excluding participants with values below 40. After exclusion, the inferences in the disconfirming condition `r report_desc(inf_stereoprob_ex_desc, 1)` were still not significantly lower than in the confirming condition `r report_desc(inf_stereoprob_ex_desc, 2)`, `r inf_stereoprob_ex_report`.

##### Descriptives
```{r target inference party stereoprob ~ typicality descriptives}
knitr::kable(inf_stereoprob_desc, format = "markdown")
```

##### Outlier Detection
```{r target inference party stereoprob ~ typicality outlier, warning = FALSE, message = FALSE, fig.width = 4}
inf_stereoprob_dat %>%
  ggplot(., aes(typicality, inf)) +
  geom_boxplot(outlier.shape = NA, color = "#465263") +
  geom_jitter(width = 0.2, color = "#465263") +
  labs(x = "Typicality", y = "Inferences") +
  theme_cs_talk()
```

##### Multiverse Outlier Correction
```{r target inference party stereoprob ~ typicality multiverse, warning = FALSE, message = FALSE}
# Loop over all combinations of cutoffs and transformations
mv_stereoprob <- data.frame(
  cutoff = c("none", "fixed 20", "fixed 30", "fixed 40",
    "Mdn Â± 2.5 IQR", "Mdn Â± 2.0 IQR", "Mdn Â± 1.5 IQR", "Mdn Â± 1.0 IQR"),
  cutoff_type = c("fixed", "fixed", "fixed", "fixed",
    "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR"),
  cutoff_value = c(0, 20, 30, 40, 2.5, 2.0, 1.5, 1.0))
for (c in seq_len(nrow(mv_stereoprob))) {
  if (mv_stereoprob$cutoff_type[c] == "fixed") {
    mv_dat <- inf_stereoprob_dat %>%
      filter(inf >= mv_stereoprob$cutoff_value[c])
  } else if (mv_stereoprob$cutoff_type[c] == "Mdn Â± IQR") {
    mv_dat <- inf_stereoprob_dat %>%
      group_by(typicality) %>%
      filter(!is_outlier(inf, coef = mv_stereoprob$cutoff_value[c])) %>%
      ungroup()
  }
  # Independent samples t-test
  mv_t <- mv_dat %>%
    t_test(
      inf ~ typicality,
      alternative = "less",
      ref.group = "DIS") %>%
    mutate(p = formp(p, text = FALSE), df = forma(df, 2),
      statistic = forma(statistic))

  # Cohens d
  mv_d <- mv_dat %>%
    cohens_d(inf ~ typicality) %>%
    pull(effsize) %>%
    forma()

  # Save test statistics for h1
  mv_stereoprob$`n excluded`[c] <- nrow(inf_stereoprob_dat) - nrow(mv_dat)
  mv_stereoprob$df[c] <- mv_t$df
  mv_stereoprob$t[c] <- mv_t$statistic
  mv_stereoprob$p[c] <- mv_t$p
  mv_stereoprob$d[c] <- mv_d
}
# Print multiverse table
knitr::kable(select(mv_stereoprob, -cutoff_type, - cutoff_value),
  format = "markdown")
```

To investigate the robustness of the effect across various outlier exclusion criteria, we conducted a multiverse analysis. We again performed independent samples t-tests across several fixed and distribution-based thresholds. The effect was non-significant across all seven thresholds. These results suggest that manipulating the stereotype probability has no effect on inferences of partisanship.

##### QQ-Plot
```{r target inference party stereoprob ~ typicality qq, message = FALSE}
inf_stereoprob_dat %>%
  ggplot(., aes(sample = inf)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#000000") +
  stat_qq_line(color = "#000000") +
  facet_grid(~ typicality, labeller = "label_value") +
  theme_cs_talk()
```

### Ideological Inferences
#### Counterstereotype Probability {.tabset}
```{r target inference ideological ~ typicality, warning = FALSE, message = FALSE}
# PREREGISTERED
# Inference data
inf_ideo_dat <- dat %>%
  filter(diagnosticity_component == "COUNTERPROB") %>%
  filter(category_type == "IDEOLOGICAL") %>%
  filter(item_type == "target")

# Descriptives
inf_ideo_desc <- inf_ideo_dat %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_ideo_t <- inf_ideo_dat %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_ideo_d <- inf_ideo_dat %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_ideo_report <- paste0("t(", inf_ideo_t$df, ") = ",
  inf_ideo_t$statistic, ", ", inf_ideo_t$p, ", d = ",
  inf_ideo_d)

# EXCLUDE OUTLIERS
inf_ideo_dat_ex <- inf_ideo_dat %>%
  filter(inf >= 40)

# Descriptives
inf_ideo_ex_desc <- inf_ideo_dat_ex %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_ideo_ex_t <- inf_ideo_dat_ex %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_ideo_ex_d <- inf_ideo_dat_ex %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_ideo_ex_report <- paste0("t(", inf_ideo_ex_t$df, ") = ",
  inf_ideo_ex_t$statistic, ", ", inf_ideo_ex_t$p, ", d = ",
  inf_ideo_ex_d)

# WILCOXON
# One-sided Wilcoxon rank-sum test
inf_ideo_wcx <- inf_ideo_dat %>%
  wilcox_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS")

# Wilcoxon effect size r
inf_ideo_wcx_r <- inf_ideo_dat %>%
  wilcox_effsize(inf ~ typicality,
  ref.group = "DIS") %>%
  pull(effsize)

# Print wilcoxon test
inf_ideo_wcx_report <- paste0("Z = ",
  forma(inf_ideo_wcx_r * sqrt(nrow(inf_ideo_dat) / 2)),
  ", ", formp(inf_ideo_wcx$p, TRUE), ", r = ", forma(inf_ideo_wcx_r))
```

To test our hypothesis in the ideological category condition, we conducted a preregistered one-sided independent samples t-test comparing target inferences of ideological categories in the stereotype-confirming and stereotype-disconfirming conditions. The target inferences in the disconfirming condition `r report_desc(inf_ideo_desc, 1)` were not significantly lower than in the stereotype-confirming condition `r report_desc(inf_ideo_desc, 2)`, `r inf_ideo_report`. To investigate whether this was due to statistical outliers, we conducted another independent samples t-test excluding participants with values below 40. After exclusion, the inferences in the disconfirming condition `r report_desc(inf_ideo_ex_desc, 1)` were significantly lower than in the confirming condition `r report_desc(inf_ideo_ex_desc, 2)`, `r inf_ideo_ex_report`.

##### Descriptives
```{r target inference ideological ~ time * typicality descriptives}
knitr::kable(inf_ideo_desc, format = "markdown")
```

##### Outlier Detection
```{r target inference ideological ~ typicality outlier, warning = FALSE, message = FALSE, fig.width = 4}
inf_ideo_dat %>%
  ggplot(., aes(typicality, inf)) +
  geom_boxplot(outlier.shape = NA, color = "#465263") +
  geom_jitter(width = 0.2, color = "#465263") +
  labs(x = "Typicality", y = "Inferences") +
  theme_cs_talk()
```

##### Multiverse Outlier Correction
```{r target inference ideological ~ typicality multiverse, warning = FALSE, message = FALSE}
# Loop over all combinations of cutoffs and transformations
mv_ideo <- data.frame(
  cutoff = c("none", "fixed 20", "fixed 30", "fixed 40",
    "Mdn Â± 2.5 IQR", "Mdn Â± 2.0 IQR", "Mdn Â± 1.5 IQR", "Mdn Â± 1.0 IQR"),
  cutoff_type = c("fixed", "fixed", "fixed", "fixed",
    "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR"),
  cutoff_value = c(0, 20, 30, 40, 2.5, 2.0, 1.5, 1.0))
for (c in seq_len(nrow(mv_ideo))) {
  if (mv_ideo$cutoff_type[c] == "fixed") {
    mv_dat <- inf_ideo_dat %>%
      filter(inf >= mv_ideo$cutoff_value[c])
  } else if (mv_ideo$cutoff_type[c] == "Mdn Â± IQR") {
    mv_dat <- inf_ideo_dat %>%
      group_by(typicality) %>%
      filter(!is_outlier(inf, coef = mv_ideo$cutoff_value[c])) %>%
      ungroup()
  }
  # Independent samples t-test
  mv_t <- mv_dat %>%
    t_test(
      inf ~ typicality,
      alternative = "less",
      ref.group = "DIS") %>%
    mutate(p = formp(p, text = FALSE), df = forma(df, 2),
      statistic = forma(statistic))

  # Cohens d
  mv_d <- mv_dat %>%
    cohens_d(inf ~ typicality) %>%
    pull(effsize) %>%
    forma()

  # Save test statistics for h1
  mv_ideo$`n excluded`[c] <- nrow(inf_ideo_dat) - nrow(mv_dat)
  mv_ideo$df[c] <- mv_t$df
  mv_ideo$t[c] <- mv_t$statistic
  mv_ideo$p[c] <- mv_t$p
  mv_ideo$d[c] <- mv_d
}
# Print multiverse table
knitr::kable(select(mv_ideo, -cutoff_type, - cutoff_value), format = "markdown")
```

To investigate the robustness of the effect across various outlier exclusion criteria, we conducted a multiverse analysis. We again performed independent samples t-tests across several fixed and distribution-based thresholds. The effect was significant across all seven thresholds. These results again suggest that the effect may have been obscured due to model outliers.

##### QQ-Plot
```{r target inference ideological ~ typicality qq, message = FALSE}
inf_ideo_dat_ex %>%
  ggplot(., aes(sample = inf)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#000000") +
  stat_qq_line(color = "#000000") +
  facet_grid(~ typicality, labeller = "label_value") +
  theme_cs_talk()
```

##### Moderation by participant ideology
```{r target inference ideological ~ typicality * ideology}
# Prepare data
inf_ideo_ideo_dat <- inf_ideo_dat_ex %>%
  mutate(ideo_cat = case_when(
    political_ideology < 35 ~ "CON",
    political_ideology > 65 ~ "LIB",
    .default = "MOD"
  ))

# Descriptives
inf_ideo_ideo_desc <- inf_ideo_ideo_dat %>%
  group_by(ideo_cat, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
inf_ideo_ideo_mod <- inf_ideo_ideo_dat %>%
  anova_test(dv = inf,
    effect.size = "pes",
    between = c(ideo_cat, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

knitr::kable(inf_ideo_ideo_mod, format = "markdown")
```

It may be possible that the effect of diagnosticity on the inferences depends on the participant's ideological category. To test this, we categorized participants with an ideology score of below 35 as conservatives, those with a score higher than 65 as liberals, and those in between as moderates and then conducted a two-way between-subjects ANOVA with the target inference as the dependent variable and the participants' ideological identification and typicality as between-subjects factors. We found a significant effect of ideological category, which was likely driven by lower inference scores of ideological moderates. Moreover, we found a significant effect of typicality.

##### Moderation by ideological fit
```{r target inference ideological ~ typicality * ideological fit}
# Prepare data
inf_ideo_fit_dat <- inf_ideo_ideo_dat %>%
  # Select participants who identify as liberal or conservative
  filter(ideo_cat %in% c("CON", "LIB")) %>%
  # Create ideological fit variable
  mutate(ideo_fit = as.factor(ifelse(
    ideo_cat == target_category_label,
    "same", "different")))

# Descriptives
inf_ideo_fit_desc <- inf_ideo_fit_dat %>%
  group_by(ideo_fit, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
inf_ideo_fit_mod <- inf_ideo_fit_dat %>%
  anova_test(dv = inf,
    effect.size = "pes",
    between = c(ideo_fit, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

knitr::kable(inf_ideo_fit_mod, format = "markdown")
```

It may be possible that the effect of diagnosticity on the inferences depends on the fit between the participant's ideological category and the target's category. We therefore ran an exploratory analysis examining the role of ideological fit (i.e., whether participant and target belong to the same category or a different one). We excluded participants classified as moderates and conducted a two-way between-subjects ANOVA with the target inference as the dependent variable and ideological fit and typicality as between-subjects factors. None of the effects were significant.

##### Moderation by political issue
```{r target inference ideological ~ typicality * issue}
# Descriptives
inf_ideo_issue_desc <- inf_ideo_dat_ex %>%
  group_by(issue, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
inf_ideo_issue_mod <- inf_ideo_dat_ex %>%
  anova_test(dv = inf,
    effect.size = "pes",
    between = c(issue, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

knitr::kable(inf_ideo_issue_mod, format = "markdown")
```

We ran another exploratory analysis to test whether the effect of diagnosticity on the inferences was moderated by the issue for which diagnosticity was manipulated. We conducted a two-way between-subjects ANOVA with the target inference as the dependent variable and issue and typicality as between-subjects factors. We found a significant effect for issue that was likely driven by lower inferences in the affirmative action condition. Moreover, we found a significant effect of typicality. The interaction was not significant.

#### Stereotype Probability {.tabset}
```{r target inference ideological stereoprob ~ typicality, warning = FALSE, message = FALSE}
# Inference data
inf_stereoprob_ideo_dat <- dat %>%
  filter(diagnosticity_component == "STEREOPROB") %>%
  filter(category_type == "IDEOLOGICAL") %>%
  filter(item_type == "target")

# Descriptives
inf_stereoprob_ideo_desc <- inf_stereoprob_ideo_dat %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_stereoprob_ideo_t <- inf_stereoprob_ideo_dat %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_stereoprob_ideo_d <- inf_stereoprob_ideo_dat %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_stereoprob_ideo_report <- paste0("t(", inf_stereoprob_ideo_t$df, ") = ",
  inf_stereoprob_ideo_t$statistic, ", ", inf_stereoprob_ideo_t$p, ", d = ",
  inf_stereoprob_ideo_d)

# EXCLUDE OUTLIERS
inf_stereoprob_ideo_dat_ex <- inf_stereoprob_ideo_dat %>%
  filter(inf >= 40)

# Descriptives
inf_stereoprob_ideo_ex_desc <- inf_stereoprob_ideo_dat_ex %>%
  group_by(typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
inf_stereoprob_ideo_ex_t <- inf_stereoprob_ideo_dat_ex %>%
  t_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_stereoprob_ideo_ex_d <- inf_stereoprob_ideo_dat_ex %>%
  cohens_d(inf ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_stereoprob_ideo_ex_report <- paste0("t(", inf_stereoprob_ideo_ex_t$df, ") = ",
  inf_stereoprob_ideo_ex_t$statistic, ", ", inf_stereoprob_ideo_ex_t$p, ", d = ",
  inf_stereoprob_ideo_ex_d)

# WILCOXON
# One-sided Wilcoxon rank-sum test
inf_stereoprob_ideo_wcx <- inf_stereoprob_ideo_dat %>%
  wilcox_test(
    inf ~ typicality,
    alternative = "less",
    ref.group = "DIS")

# Wilcoxon effect size r
inf_stereoprob_ideo_wcx_r <- inf_stereoprob_ideo_dat %>%
  wilcox_effsize(inf ~ typicality,
  ref.group = "DIS") %>%
  pull(effsize)

# Print wilcoxon test
inf_stereoprob_ideo_wcx_report <- paste0("Z = ",
  forma(inf_stereoprob_ideo_wcx_r * sqrt(nrow(inf_stereoprob_ideo_dat) / 2)),
  ", ", formp(inf_stereoprob_ideo_wcx$p, TRUE),
  ", r = ", forma(inf_stereoprob_ideo_wcx_r))
```

To test the effect of manipulating the stereotype probability component of diagnosticity on inferences of partisanship, we conducted an exploratory one-sided independent samples t-test comparing target inferences of ideological categories in the stereotype-confirming and stereotype-disconfirming conditions. The target inferences in the disconfirming condition `r report_desc(inf_stereoprob_ideo_desc, 1)` were not significantly lower than in the stereotype-confirming condition `r report_desc(inf_stereoprob_ideo_desc, 2)`, `r inf_stereoprob_ideo_report`. To investigate whether this was due to statistical outliers, we conducted another independent samples t-test excluding participants with values below 40. After exclusion, the inferences in the disconfirming condition `r report_desc(inf_stereoprob_ideo_ex_desc, 1)` were still not significantly lower than in the confirming condition `r report_desc(inf_stereoprob_ideo_ex_desc, 2)`, `r inf_stereoprob_ideo_ex_report`.

##### Descriptives
```{r target inference ideological stereoprob ~ typicality descriptives}
knitr::kable(inf_stereoprob_ideo_desc, format = "markdown")
```

##### Outlier Detection
```{r target inference ideological stereoprob ~ typicality outlier, warning = FALSE, message = FALSE, fig.width = 4}
inf_stereoprob_ideo_dat %>%
  ggplot(., aes(typicality, inf)) +
  geom_boxplot(outlier.shape = NA, color = "#465263") +
  geom_jitter(width = 0.2, color = "#465263") +
  labs(x = "Typicality", y = "Inferences") +
  theme_cs_talk()
```

##### Multiverse Outlier Correction
```{r target inference ideological stereoprob ~ typicality multiverse, warning = FALSE, message = FALSE}
# Loop over all combinations of cutoffs and transformations
mv_stereoprob_ideo <- data.frame(
  cutoff = c("none", "fixed 20", "fixed 30", "fixed 40",
    "Mdn Â± 2.5 IQR", "Mdn Â± 2.0 IQR", "Mdn Â± 1.5 IQR", "Mdn Â± 1.0 IQR"),
  cutoff_type = c("fixed", "fixed", "fixed", "fixed",
    "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR", "Mdn Â± IQR"),
  cutoff_value = c(0, 20, 30, 40, 2.5, 2.0, 1.5, 1.0))
for (c in seq_len(nrow(mv_stereoprob_ideo))) {
  if (mv_stereoprob_ideo$cutoff_type[c] == "fixed") {
    mv_dat <- inf_stereoprob_ideo_dat %>%
      filter(inf >= mv_stereoprob_ideo$cutoff_value[c])
  } else if (mv_stereoprob_ideo$cutoff_type[c] == "Mdn Â± IQR") {
    mv_dat <- inf_stereoprob_ideo_dat %>%
      group_by(typicality) %>%
      filter(!is_outlier(inf, coef = mv_stereoprob_ideo$cutoff_value[c])) %>%
      ungroup()
  }
  # Independent samples t-test
  mv_t <- mv_dat %>%
    t_test(
      inf ~ typicality,
      alternative = "less",
      ref.group = "DIS") %>%
    mutate(p = formp(p, text = FALSE), df = forma(df, 2),
      statistic = forma(statistic))

  # Cohens d
  mv_d <- mv_dat %>%
    cohens_d(inf ~ typicality) %>%
    pull(effsize) %>%
    forma()

  # Save test statistics for h1
  mv_stereoprob_ideo$`n excluded`[c] <-
    nrow(inf_stereoprob_ideo_dat) - nrow(mv_dat)
  mv_stereoprob_ideo$df[c] <- mv_t$df
  mv_stereoprob_ideo$t[c] <- mv_t$statistic
  mv_stereoprob_ideo$p[c] <- mv_t$p
  mv_stereoprob_ideo$d[c] <- mv_d
}
# Print multiverse table
knitr::kable(select(mv_stereoprob_ideo, -cutoff_type, - cutoff_value),
  format = "markdown")
```

To investigate the robustness of the effect across various outlier exclusion criteria, we conducted a multiverse analysis. We again performed independent samples t-tests across several fixed and distribution-based thresholds. The effect was not significant for all of the seven thresholds. These results suggest that manipulating the stereotype probability has no effect on inferences of partisanship.

##### QQ-Plot
```{r target inference ideological stereoprob ~ typicality qq, message = FALSE}
inf_stereoprob_ideo_dat %>%
  ggplot(., aes(sample = inf)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#000000") +
  stat_qq_line(color = "#000000") +
  facet_grid(~ typicality, labeller = "label_value") +
  theme_cs_talk()
```

##### Diagnosticity Simulation
```{r diagnosticity simulation, fig.height = 18}
# Expected condition means
diag_dat <- dat %>%
  filter(item_type == "target") %>%
  filter(inf >= 40)
# Get observed condition means
diag_desc <- diag_dat %>%
  group_by(diagnosticity_component, typicality) %>%
  get_summary_stats(inf, type = "mean_sd")
# Compute change in diagnosticity
diag <- data.frame(
  # Stereotype probability
  probA = rep(seq(0.1, 0.9, 0.02), each = 1681),
  # Counterstereotype probability
  probB = rep(rep(seq(0.1, 0.9, 0.02), each = 41), times = 41),
  # Change in probability
  incr = rep(seq(0.04, 0.08, 0.001), times = 1681)) %>%
  # Remove cases that are diagnostic of other category
  filter(probA > probB) %>%
  # Compute diagnosticity at baseline and with changed probs
  mutate(
    base = probA / (probA + probB),
    incr_counter = probA / (probA + (probB + incr)),
    decr_stereo = (probA - incr) / ((probA - incr) + probB)) %>%
  # Compute increase compared to baseline
  mutate(
    incr_counter_effect = base - incr_counter,
    decr_stereo_effect = base - decr_stereo) %>%
  # Find set of probabilities closest to observed condition means
  mutate(abs_total_dist =
    abs(base - diag_desc$mean[2] / 100) +
    abs(base - diag_desc$mean[4] / 100) +
    abs(incr_counter - diag_desc$mean[1] / 100) +
    abs(decr_stereo - diag_desc$mean[3] / 100))
diag_winner <- diag %>%
  filter(abs_total_dist == min(abs_total_dist))
diag <- diag %>%
  filter(incr == diag_winner$incr)

library(plot3D)
par(mfrow = c(2, 1))
scatter3D(x = diag$probB, y = diag$probA, z = diag$decr_stereo_effect,
  pch = 16,
  ticktype = "detailed",
  xlab = "Stereotype Probability",
  ylab = "Counterstereotype Probability",
  zlab = "Change in Diagnosticity",
  clab = "Diagnosticity",
  colvar = diag$base,
  col = ramp.col(col = c("#2d85ff", "#28ea96"), n = 100, alpha = 1),
  main = "Change in diagnosticity due to decreasing stereotype probability")
scatter3D(x = diag$probB, y = diag$probA, z = diag$incr_counter_effect,
  pch = 16,
  ticktype = "detailed",
  xlab = "Counterstereotype Probability",
  ylab = "Stereotype Probability",
  zlab = "Change in Diagnosticity",
  clab = "Diagnosticity",
  colvar = diag$base,
  col = ramp.col(col = c("#2d85ff", "#28ea96"), n = 100, alpha = 1),
  main = "Change in diagnosticity due to increasing counterstereotype probability")
```

Decreasing the stereotype probability leads to larger decreases of diagnosticity the smaller the stereotype probability and the closer the two probabilities are together. Generally, these are cases with low diagnosticity. Increasing the counterstereotype probability the other hand leads to larger decreases of diagnosticity the smaller the counterstereotype probability and the further the two probabilities are apart. Generally these are cases with high diagnosticity. As the opinions presented in the current study are highly diagnostic, it would be expected on account of the diagnosticity formula, that decreasing the stereotype probability produces smaller decrease in diagnosticity compared to increasing the counterstereotype probability.

### Analyses Across Category Types
#### Moderation by Category Type and Diagnosticity Component {.tabset}
```{r target inference ~ typicality * category_type * diagnosticity_component, warning = FALSE, message = FALSE}
# Inference data
full_dat <- dat %>%
  filter(item_type == "target") %>%
  filter(inf >= 40)

# Descriptives
full_desc <- full_dat %>%
  select(category_type, diagnosticity_component, typicality, inf) %>%
  group_by(category_type, diagnosticity_component, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
full_mod <- full_dat %>%
  anova_test(dv = inf,
    wid = subject_id,
    effect.size = "pes",
    within = diagnosticity_component,
    between = c(category_type, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))
```

To test whether the effect of typicality was moderated by category type or diagnosticity component, we conducted a three-way mixed ANOVA with the target inferences as the dependent variable, typicality and category type as between-subjects factors, and diagnosticity component as a within-subjects factor. We obtained a significant effect for typicality, F(`r full_mod$DFn[2]`, `r full_mod$DFd[2]`) = `r full_mod$F[2]`, `r formp(full_mod$p[2])`, $\eta_{p}^{2}$ = `r full_mod$pes[2]`, a significant effect for diagnosticity component, F(`r full_mod$DFn[3]`, `r full_mod$DFd[3]`) = `r full_mod$F[3]`, `r formp(full_mod$p[3])`, $\eta_{p}^{2}$ = `r full_mod$pes[3]`, and a significant interaction between category type and diagnosticity component, F(`r full_mod$DFn[5]`, `r full_mod$DFd[5]`) = `r full_mod$F[5]`, `r formp(full_mod$p[5])`, $\eta_{p}^{2}$ = `r full_mod$pes[5]`. All other effects were non-significant.

##### Neutral Typicality Condition
```{r target inference ~ typicality * item_type, warning = FALSE, message = FALSE}
# Prepare inference data
neu_dat <- dat %>%
  # Drop stereotype probability condition
  filter(diagnosticity_component == "COUNTERPROB") %>%
  # Drop filler trials
  filter(item_type %in% c("target", "test")) %>%
  mutate(item_type = droplevels(item_type)) %>%
  # Outlier exclusion
  filter(inf >= 40) %>%
  # Exclude incomplete participants
  group_by(subject_id) %>%
  filter(n() > 2) %>%
  ungroup()

# Find cell (typicality * issue) with lowest number of participants
min_count <- neu_dat %>%
  group_by(issue, typicality) %>%
  summarise(.groups = "drop", n = n() / 3) %>%
  pull(n) %>%
  min()

# Sample same number of participants for each cell (typicality * issue)
set.seed(0)
include_ids <- neu_dat %>%
  select(subject_id, issue, typicality) %>%
  unique() %>%
  group_by(issue, typicality) %>%
  slice_sample(n = min_count) %>%
  ungroup() %>%
  pull(subject_id)

# Create balanced dataset
neu_dat_balanced <- neu_dat %>%
  filter(subject_id %in% include_ids) %>%
  # Average test items
  group_by(subject_id, typicality, item_type) %>%
  summarize(.groups = "drop", inf = mean(inf))

# Descriptives
neu_desc <- neu_dat_balanced %>%
  select(item_type, typicality, inf) %>%
  group_by(item_type, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
neu_mod <- neu_dat_balanced %>%
  anova_test(dv = inf,
    wid = subject_id,
    effect.size = "pes",
    within = item_type,
    between = typicality) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))

# Simple Effects Tests
# Dependent samples t-test
neu_dis_t <- neu_dat_balanced %>%
  filter(typicality == "DIS") %>%
  t_test(
    inf ~ item_type, paired = TRUE,
    alternative = "less",
    ref.group = "target") %>%
  mutate(p = formp(p, text = TRUE), statistic = forma(statistic))
neu_con_t <- neu_dat_balanced %>%
  filter(typicality == "CON") %>%
  t_test(
    inf ~ item_type, paired = TRUE,
    alternative = "greater",
    ref.group = "target") %>%
  mutate(p = formp(p, text = TRUE), statistic = forma(statistic))

# Cohens dz
neu_dis_dz <- neu_dat_balanced %>%
  filter(typicality == "DIS") %>%
  cohens_d(inf ~ item_type, paired = TRUE) %>%
  pull(effsize) %>%
  forma()
neu_con_dz <- neu_dat_balanced %>%
  filter(typicality == "CON") %>%
  cohens_d(inf ~ item_type, paired = TRUE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
neu_dis_report <- paste0("t(", neu_dis_t$df, ") = ",
  neu_dis_t$statistic, ", ", neu_dis_t$p, ", d~z~ = ",
  neu_dis_dz)
neu_con_report <- paste0("t(", neu_con_t$df, ") = ",
  neu_con_t$statistic, ", ", neu_con_t$p, ", d~z~ = ",
  neu_con_dz)
```

Our diagnosticity manipulation had no baseline condition. In polarized societies like the US, people should be much more likely to be confronted with stereotype confirming information than with stereotype disconfirming information. Therefore it could be argued that the confirming condition is unlikely to have made inferences stronger. To nevertheless test whether the counterstereotype truly leads to a decrease in diagnosticity, we compared the target inference item with the two test items for which diagnosticity had not been manipulated for the respective participant. As these items are the target items for other participants, this method controls for differences in baseline diagnosticity between the different items. To further prevent such differences from biasing the results, we used random sampling to obtain a balanced dataset in which the three issues were presented equally often as target and distractor items. We conducted a two-way mixed ANOVA with the inferences as the dependent variable, typicality as a between-subjects factor, and item type as a within-subjects factor. We obtained a significant effect for typicality, F(`r neu_mod$DFn[1]`, `r neu_mod$DFd[1]`) = `r neu_mod$F[1]`, `r formp(neu_mod$p[1])`, $\eta_{p}^{2}$ = `r neu_mod$pes[1]`, and a significant interaction, F(`r neu_mod$DFn[3]`, `r neu_mod$DFd[3]`) = `r neu_mod$F[3]`, `r formp(neu_mod$p[3])`, $\eta_{p}^{2}$ = `r neu_mod$pes[3]`. There was no significant effect of item type, F(`r neu_mod$DFn[2]`, `r neu_mod$DFd[2]`) = `r neu_mod$F[2]`, `r formp(neu_mod$p[2])`, $\eta_{p}^{2}$ = `r neu_mod$pes[2]`,

Simple effects analyses revealed that the effect of item type was significant and negative in the stereotype disconfirming condition `r neu_dis_report`, indicating that counterstereotypical exemplars did reduce inferences compared to the baseline level. In the stereotype confirming condition the effect was positive and non-significant `r neu_con_report`, indicating that stereotypical exemplars did not increase inferences compared to baseline level. This suggests that the effect may be more strongly driven by a reduction of inferences due to the counterstereotypical exemplars rather than by an increase of inferences due to the stereotypical ones.

##### Compare to Expected Value
```{r simulation, message = FALSE, warning = FALSE}
# Prepare observed data for counterstereotype probability condition
sim_dat <- dat %>%
  filter(item_type == "target") %>%
  filter(diagnosticity_component == "COUNTERPROB") %>%
  select(subject_id, typicality, inf) %>%
  mutate(inf = ifelse(inf >= 40, inf / 100, NA)) %>%
  pivot_wider(names_glue = "{typicality}_COUNTERPROB",
    names_from = c(typicality),
    values_from = inf) %>%
  select(-subject_id)

# Compute observed condition means and variances
mus <- colMeans(sim_dat, na.rm = TRUE)
vars <- unlist(lapply(sim_dat, var, na.rm = TRUE))

# Calculate parameters for the Beta distribution
alphas <- ((mus * (1 - mus)) / vars - 1) * mus
betas <- ((mus * (1 - mus)) / vars - 1) * (1 - mus)

# Compute change in diagnosticity
diag <- data.frame(
  # Stereotype probability
  probA = rep(seq(0.01, 1, 0.01), each = 10000),
  # Counterstereotype probability
  probB = rep(rep(seq(0.01, 1, 0.01), each = 100), times = 100),
  # Change in probability
  incr = rep(seq(0.01, 1, 0.01), times = 10000)) %>%
  # Remove cases that are diagnostic of other category
  filter(probA >= probB) %>%
  # Remove cases that would have a negative stereotype probability
  filter(probA - incr >= 0) %>%
  # Compute diagnosticity at baseline and with changed probs
  mutate(
    CON_COUNTERPROB = probA / (probA + probB),
    CON_STEREOPROB = probA / (probA + probB),
    DIS_COUNTERPROB = probA / (probA + (probB + incr)),
    DIS_STEREOPROB = (probA - incr) / ((probA - incr) + probB)) %>%
  # Compute increase compared to baseline
  mutate(
    counterprob_effect = DIS_COUNTERPROB - CON_COUNTERPROB,
    stereoprob_effect = DIS_STEREOPROB - CON_STEREOPROB)

# Define model function
sim <- function(n = 360, alphas, betas, diag) {
  # Simulate skewed data using beta distribution
  d <- data.frame(
      CON = rbeta(n / 2, alphas[1], betas[1]),
      DIS = rbeta(n / 2, alphas[2], betas[2]))

  # Select probabilities that best match the simulated data
  winner <- diag %>%
    # Calculate absolute total distance
    mutate(abs_total_dist =
      abs(CON_COUNTERPROB - mean(d$CON)) +
      abs(DIS_COUNTERPROB - mean(d$DIS))) %>%
    # Choose values with smallest absolute total distance
    filter(abs_total_dist == min(abs_total_dist, na.rm = TRUE)) %>%
    # Calculate means for simulated data
    mutate(mean_con = mean(d$CON), mean_dis = mean(d$DIS)) %>%
    mutate(var_con = var(d$CON), var_dis = var(d$DIS)) %>%
    # Calculate expected
    # Select variables to return
    select(
      probA, probB, incr, counterprob_effect, stereoprob_effect,
      mean_con, mean_dis, var_con, var_dis)

  # Return best match (in case of ties, randomly sample one)
  return(slice_sample(winner))
}

# Run simulation
result <- data.frame()
RNGkind("L'Ecuyer-CMRG")
result <- mclapply(X = rep(360, 10000),
  FUN = sim, alphas = alphas, betas = betas, diag = diag,
  mc.cores = 8, mc.set.seed = TRUE) %>%
  do.call(rbind, .) %>%
  as.data.frame()

# Get summary stats for simulation results
result_desc <- result %>%
  get_summary_stats(everything(), type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Prepare observed data for stereotype probability condition
inf_stereoprob_expect <- dat %>%
  filter(item_type == "target") %>%
  filter(diagnosticity_component == "STEREOPROB") %>%
  select(subject_id, typicality, inf) %>%
  filter(inf >= 40)

# Get summary stats
inf_stereoprob_expect_desc <- inf_stereoprob_expect %>%
  group_by(typicality) %>%
  get_summary_stats(everything(), type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test against expected value
inf_stereoprob_expect_t <- inf_stereoprob_expect %>%
  t_test(
    inf ~ typicality,
    mu = result_desc$mean[5] * 100,
    alternative = "two.sided",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
inf_stereoprob_expect_d <- inf_stereoprob_expect %>%
  mutate(inf = ifelse(
    typicality == "CON",
    inf + result_desc$mean[5] * 100,
    inf)) %>%
  cohens_d(inf ~ typicality) %>%
  pull(effsize) %>%
  forma()

# Print t-test
inf_stereoprob_expect_report <- paste0("t(", inf_stereoprob_expect_t$df, ") = ",
  inf_stereoprob_expect_t$statistic, ", ", inf_stereoprob_expect_t$p, ", d = ",
  inf_stereoprob_expect_d)
```

The effect of manipulating the stereotype probability component of diagnosticity on the strength of the inferences should be smaller than that of manipulating the counterstereotype probability componentâ€”at least in a context with highly diagnostic cues. To calculate how much smaller this effect should be, we ran a simulation. First, we calculated the expected condition means for a range of different baseline probabilities (P(cue|category A) and P(cue|category B)) and intervention effects (i.e., changes in these probabilities)â€“assuming that a diagnosticity of 0.5 would correspond to an inference score of 50 and a diagnosticity of 1 to an inference score of 100. We then simulated 10000 datasets based on the observed means and standard deviations of the counterstereotype probability condition. To account for the skewness of the data we used a beta distribution. For each simulated dataset we compared the simulated condition means to the expected condition means and selected the combination of baseline probabilities and intervention effects for which the simulated and expected condition means were closest to each other. We then computed the means of the baseline probabilities, intervention effects, and the expected effects for the counterstereotype and stereotype probability conditions. This procedure suggested that for a population with the observed means and variances the stereotype probability would be `r forma(result_desc$mean[1] * 100, 0)`%, the counterstereotype probability would be `r forma(result_desc$mean[2] * 100, 0)`%, and the change in probabilities would be `r forma(result_desc$mean[3] * 100, 1)`%. Given these values the expected effect in the stereotype probability condition would be `r forma(result_desc$mean[4] / result_desc$mean[5], 1)` times smaller than the effect in the counterstereotype probability condition. To test whether the observed effect significantly differed from the expected effect, we conducted a two-sided independent samples t-test testing whether the difference between target inferences in the stereotype-confirming and stereotype-disconfirming conditions was larger than `r forma(result_desc$mean[5])` (the expected effect). The difference between the disconfirming condition `r report_desc(inf_stereoprob_expect_desc, 1)` and the confirming condition `r report_desc(inf_stereoprob_expect_desc, 2)` did not significantly differ from the expected difference `r inf_stereoprob_expect_report`.

##### Moderation by typicality rating
```{r target inference ~ typicality * typicality_rating, message = FALSE, warning = FALSE}
# Inference data
inf_typ_dat <- dat %>%
  filter(diagnosticity_component == "COUNTERPROB") %>%
  filter(item_type == "target") %>%
  filter(inf >= 40) %>%
  group_by(typicality) %>%
  mutate(typicality_bin = ntile(typicality_target, 2)) %>%
  mutate(typicality_bin = factor(typicality_bin, labels = c("low", "high"))) %>%
  ungroup() %>%
  mutate(typicality_target_c = typicality_target - 50)

# DV: Typicality
# Descriptives
typ_desc <- inf_typ_dat %>%
  group_by(typicality) %>%
  get_summary_stats(typicality_target, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Independent samples t-test
typ_t <- inf_typ_dat %>%
  t_test(
    typicality_target ~ typicality,
    alternative = "less",
    ref.group = "DIS") %>%
  mutate(p = formp(p, text = TRUE), df = forma(df, 2),
    statistic = forma(statistic))

# Cohens d
typ_d <- inf_typ_dat %>%
  cohens_d(typicality_target ~ typicality, paired = FALSE) %>%
  pull(effsize) %>%
  forma()

# Print t-test
typ_report <- paste0("t(", typ_t$df, ") = ",
  typ_t$statistic, ", ", typ_t$p, ", d = ",
  typ_d)

# DV: Inferences
inf_typ_desc <- inf_typ_dat %>%
  group_by(typicality_bin, typicality) %>%
  get_summary_stats(inf, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run regression
contrasts(inf_typ_dat$typicality) <- c(1, 0)
inf_typ_mod <- lm(
    data = inf_typ_dat,
    inf ~ typicality * typicality_target_c)
inf_typ_mod_coefs <- summary(inf_typ_mod)$coefficients %>%
  as_tibble() %>%
  rowwise() %>%
  transmute(
    predictor = "var", estimate = forma(`Estimate`, 2),
    SE = forma(`Std. Error`, 2), t = forma(`t value`, 2),
    p = formp(`Pr(>|t|)`)) %>%
  ungroup() %>%
  mutate(predictor = c("intercept", "typicality CON -> DIS",
    "typicality rating LOW -> HIGH", "interaction"))

# Plot
inf_typ_dat %>%
  ggplot(aes(x = typicality_target, y = inf, color = typicality)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE,
    aes(group = typicality)) +
  labs(
    title = "Moderation by typicality rating",
    x = "Typicality rating",
    y = "Inference",
    color = "Typicality") +
  scale_color_manual(values = c("#849AB9", "#67d1b8")) +
  theme_cs_talk()
```

The target person's perceived typicality in the disconfirming condition `r report_desc(typ_desc, 1)` was significantly lower than in the confirming condition `r report_desc(typ_desc, 2)`, `r typ_report`. To explore the effect of the typicality ratings on inference making, we ran a linear regression model with the inferences as the dependent variable and typicality, the typicality rating, and the interaction between the two as predictors. We used treatment-coding for typicality and scale midpoint centering for the typicality ratings. The overall model was significant, F(`r forma(summary(inf_typ_mod)$fstatistic[2], 0)`, `r forma(summary(inf_typ_mod)$fstatistic[3], 0)`) = `r forma(summary(inf_typ_mod)$fstatistic[1], FALSE)`, p = `r formp(pf(summary(inf_typ_mod)$fstatistic[1], summary(inf_typ_mod)$fstatistic[2], summary(inf_typ_mod)$fstatistic[3], lower.tail = FALSE))`, R^2^ = `r forma(summary(inf_typ_mod)$r.squared, FALSE)`. The main effect of typicality was not significant, b = `r inf_typ_mod_coefs$estimate[2]`, SE = `r inf_typ_mod_coefs$SE[2]`, t(`r forma(summary(inf_typ_mod)$fstatistic[3], 0)`) = `r inf_typ_mod_coefs$t[2]`, `r formp(inf_typ_mod_coefs$p[2])`, indicating that inferences were not weaker in the disconfirming condition at a medium perceived typicality. The main effect of perceived typicality was significant, b = `r inf_typ_mod_coefs$estimate[3]`, SE = `r inf_typ_mod_coefs$SE[3]`, t(`r forma(summary(inf_typ_mod)$fstatistic[3], 0)`) = `r inf_typ_mod_coefs$t[3]`, `r formp(inf_typ_mod_coefs$p[3])`, indicating that in the stereotype-confirming condition higher perceived typicality was associated with stronger inferences. Importantly, the interaction effect was significant, b = `r inf_typ_mod_coefs$estimate[4]`, SE = `r inf_typ_mod_coefs$SE[4]`, t(`r forma(summary(inf_typ_mod)$fstatistic[3], 0)`) = `r inf_typ_mod_coefs$t[4]`, `r formp(inf_typ_mod_coefs$p[4])`, indicating that in the disconfirming condition this relation was canceled out.

### Likability 
#### Category Fit * Typicality {.tabset}
```{r likability ~ time * typicality * category_fit, warning = FALSE, message = FALSE}
# Stereotype data
like_dat <- dat %>%
  select(subject_id, target_category_label, target_category,
    partisan_identity, political_ideology,
    category_type, typicality, issue, matches("_like_")) %>%
  unique() %>%
  # Exclude participants who gave same rating in all likability ratings
  rowwise() %>%
  filter(
    !all(
      t1_like_nontarget == t1_like_target,
      t1_like_target == t2_like_nontarget,
      t2_like_nontarget == t2_like_target)) %>%
  ungroup() %>%
  pivot_longer(
    cols = matches("_like_"),
    names_to = c("time", ".value", "person"),
    names_pattern = "([a-z0-9]*)_(like)_(.*)") %>%
  mutate(participant_category = case_when(.default = "OTH",
    category_type == "PARTY" &
      partisan_identity == "Independent" ~ "IND",
    category_type == "PARTY" &
      partisan_identity == "Republican" ~ "REP",
    category_type == "PARTY" &
      partisan_identity == "Democrat" ~ "DEM",
    category_type == "IDEOLOGICAL" &
      (political_ideology <= 65 & political_ideology >= 35) ~ "MOD",
    category_type == "IDEOLOGICAL" &
      (political_ideology > 65) ~ "LIB",
    category_type == "IDEOLOGICAL" &
      (political_ideology < 35) ~ "CON")) %>%
  filter(!participant_category %in% c("MOD", "IND", "OTH")) %>%
  mutate(category_fit = as.factor(ifelse(
    participant_category == target_category_label,
    "ingroup", "outgroup"))) %>%
  filter(person == "target")

# Descriptives
like_desc <- like_dat %>%
  group_by(category_fit, typicality, time) %>%
  get_summary_stats(like, type = "mean_sd") %>%
  mutate(
    ci95_low = mean - 1.96 * sd / sqrt(n),
    ci95_upp = mean + 1.96 * sd / sqrt(n))

# Run ANOVA
like_mod <- like_dat %>%
  anova_test(dv = like,
    wid = subject_id,
    effect.size = "pes",
    within = time,
    between = c(category_fit, typicality)) %>%
  as_tibble() %>%
  rowwise() %>%
  mutate(F = forma(`F`, 2), p = formp(p), pes = forma(pes, 3, FALSE))
```

##### Descriptives
```{r likability ~ time * typicality * category_fit descriptives}
knitr::kable(like_desc, format = "markdown")
```

##### Outlier Detection
```{r likability ~ time * typicality * category_fit outlier, warning = FALSE, message = FALSE}
like_dat %>%
  ggplot(., aes(typicality, like, color = time)) +
  facet_wrap(~ category_fit) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(position = position_jitterdodge()) +
  labs(x = "Typicality", y = "Stereotype") +
  scale_color_manual(values = c("#849AB9", "#465263")) +
  theme_cs_talk()
```

##### QQ-Plot
```{r likability ~ time * typicality * category_fit qq, message = FALSE}
like_dat %>%
  ggplot(., aes(sample = like)) +
  labs(x = "Theoretical quantiles", y = "Data quantiles") +
  stat_qq(color = "#000000") +
  stat_qq_line(color = "#000000") +
  facet_grid(category_fit * typicality ~ time, labeller = "label_value") +
  theme_cs_talk()
```

##### ANOVA
```{r likability ~ time * typicality * category_fit anova}
knitr::kable(like_mod, format = "markdown")
```

##### Histogram
```{r likability ~ time * typicality * category_fit histogram}
like_dat %>%
  mutate(like_bin = cut(like,
    breaks = 9, labels = FALSE, include.lowest = TRUE)) %>%
  ggplot() +
  geom_bar(position = position_dodge(preserve = "single"),
  aes(x = like_bin, y = after_stat(prop), fill = time), width = 0.8) +
  labs(title = "Histogramm of Likability Scores",
    x = "Likability (binned)",
    y = "Proportion", fill = "Time") +
  facet_grid(category_fit ~ typicality, labeller = "label_value") +
  scale_fill_manual(values = c("#849AB9", "#465263")) +
  theme_cs_talk() +
  theme(axis.text.x = element_blank())
```